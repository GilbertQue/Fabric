{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf71bbf-d90d-4e8c-bb4f-b02e272e8adb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Load mssparkutils\n",
    "import notebookutils\n",
    "\n",
    "# Get the current workspace ID\n",
    "workspace_id = notebookutils.runtime.context.get(\"currentWorkspaceId\")\n",
    "# print(f'Workspace ID: {workspace_id}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d1420-990a-46a5-8cda-d1f7e096af23",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "######################################################################################### \n",
    "# Read secretes from Azure Key Vault\n",
    "#########################################################################################\n",
    "## This is the name of my Azure Key Vault \n",
    "key_vault = \"https://domain.vault.azure.net/\"\n",
    "## I have stored my tenant id as one of the secrets to make it easier to use when needed \n",
    "tenant = mssparkutils.credentials.getSecret(key_vault , \"tenantid\") \n",
    "## This is my application Id for my service principal account \n",
    "client = mssparkutils.credentials.getSecret(key_vault , \"pbi-sp-applicationid\") \n",
    "## This is my Client Secret for my service principal account \n",
    "client_secret = mssparkutils.credentials.getSecret(key_vault , \"powerbi-sp-clientsecret\")  \n",
    "\n",
    "######################################################################################### \n",
    "# Authentication - Replace string variables with your relevant values \n",
    "#########################################################################################  \n",
    "\n",
    "import json, requests, pandas as pd \n",
    "import datetime  \n",
    "\n",
    "try: \n",
    "    from azure.identity import ClientSecretCredential \n",
    "except Exception:\n",
    "     !pip install azure.identity \n",
    "     from azure.identity import ClientSecretCredential \n",
    "\n",
    "# Generates the access token for the Service Principal \n",
    "api = 'https://analysis.windows.net/powerbi/api/.default' \n",
    "auth = ClientSecretCredential(authority = 'https://login.microsoftonline.com/', \n",
    "               tenant_id = tenant, \n",
    "               client_id = client, \n",
    "               client_secret = client_secret) \n",
    "access_token = auth.get_token(api)\n",
    "access_token = access_token.token \n",
    "\n",
    "## This is where I store my header with the Access Token, because this is required when authenticating \n",
    "## to the Power BI Admin APIs \n",
    "header = {'Authorization': f'Bearer {access_token}'}  \n",
    "\n",
    "print('\\nSuccessfully authenticated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d078a-bb03-4dbd-bcc9-d839cca2bc87",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create Case Insensitive Warehouse\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# API to Create Warehouse\n",
    "api_url = f\"https://api.fabric.microsoft.com/v1/workspaces/{workspace_id}/items\"\n",
    "\n",
    "display(api_url)\n",
    "\n",
    "# JSON Payload to Post to create the Case Insensitive Collation\n",
    "payload = { \n",
    "  \"type\": \"warehouse\", \n",
    "  \"displayName\": \"WH_Service_Principal\", \n",
    "  \"description\": \"New Lakehouse Service Principal case-insensitive collation\", \n",
    "  \"creationPayload\": { \n",
    "    \"defaultCollation\": \"Latin1_General_100_CI_AS_KS_WS_SC_UTF8\" \n",
    "  } \n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {access_token}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Checking the Payload Looks Good\n",
    "display(payload)\n",
    "\n",
    "# Post the API Response to create the Warehouse\n",
    "response = requests.post(api_url, headers=headers, json=payload)\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {},
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
